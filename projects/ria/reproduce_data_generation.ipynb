{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Воспроизведение получения данных для исследования ЦПУР «Качество проведения оценки регулирующего воздействия в России: что показывает сплошной анализ текстовых данных?»\n",
    "\n",
    "Этот ноутбук – единая точка запуска всех скриптов, которые __собирают и обрабатывают данные__ с regulation.gov.ru и sozd.duma.gov.ru для дальнейшего использования в анализе.\n",
    "\n",
    "Ноутбук состоит из трех частей: __инициализации__, __получения датасета__, аналогичного датасету, [опубликованному на сайте ИНИД]('https://data-in.ru/data-catalog/datasets/177/'), и __нормализации__ заполнений граф сводных отчетов на отсутствующие, мусорные и содержательные.\n",
    "\n",
    "Получение датасета реализовано двумя способами: полной перегенерацией датасета, воспроизводящей работу аналитиков ЦПУР, и скачиванием датасета с сайта ИНИД.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Важно:</b> Сбор исходного датасета, размещённого на ИНИД, занимает <b>длительное время</b>: требуется обойти несколько тысяч страниц электронных порталов, а затем конвертировать, распознавать и парсить длинные документы. Поэтому рекомендуем пропустить эту часть и вместо неё переходить к части «Вариант 2: скачать датасеты с ИНИД»\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление:\n",
    "* [Инициализация](#test)\n",
    "* [Вариант 1: скачать датасеты с ИНИД](#data-in-download)\n",
    "* [Вариант 2: полностью перегенерировать данные](#full-data-gen)\n",
    "* [Нормализация](#norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка зависимостей и инициализация <a class=\"anchor\" id=\"test\"></a>\n",
    "\n",
    "У этого скрипта есть несколько зависимостей: как стандартных, которые можно поставить через `pip`, так и другой собственный репозиторий ЦПУР. При запуске блока кода ниже всё поставится само.\n",
    "\n",
    "Если в какой-то момент выполнения кода вы увидите ошибку, что вам не хватает некого питоновского пакета, вы можете дописать его название в новую строчку файла `pip-requirements.txt` и снова запустить этот блок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Установим стандартные библиотеки через pip\n",
    "!pip install --quiet -r pip-requirements.txt\n",
    "\n",
    "# Установим библиотеку, разработанную ЦПУР для анализа отчётов\n",
    "!./install_report_parser.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как выполнять следующий этап, проверьте, что вы заполнили всё, что хотели, в конфигурационном файле `config.json` (подробнее см. `README.md`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим конфигурационный файл\n",
    "import json\n",
    "\n",
    "config = json.load(open('config.json', 'r'))\n",
    "workdir = config['working_directory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в PYTHONPATH ссылки на вспомогательные скрипты\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "relative_lib_paths = ['utils/report_parser/',\n",
    "                      'utils/cleanup_utils/',\n",
    "                      'utils',\n",
    "                      'scraping',\n",
    "                      'gathering',\n",
    "                      'normalization'\n",
    "                     ]\n",
    "\n",
    "absolute_lib_paths = [os.path.abspath(x) for x in relative_lib_paths]\n",
    "for path in absolute_lib_paths:\n",
    "    sys.path.insert(0, path)\n",
    "\n",
    "from utils.report_parser.report import Report\n",
    "# Протестируем, что Report загрузился\n",
    "report_example = 'utils/report_parser/examples/report.html'\n",
    "Report(report_example)\n",
    "\n",
    "from utils.db_helper import DBHelper\n",
    "# Протестируем, что DBHelper загрузился\n",
    "_ = DBHelper(config['database'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим рабочую папку, если её ещё нет\n",
    "\n",
    "if not os.path.isdir(workdir):\n",
    "    os.mkdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим другие полезные вещи\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вариант 1: скачать датасеты с ИНИД <a class=\"anchor\" id=\"data-in-download\"></a>\n",
    "\n",
    "В следующем блоке данные загрузятся с сайта каталога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачаем и сложим датасеты в workdir/datasets\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "data_dir = os.path.join(workdir, 'datasets/')\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "url = '''\n",
    "https://ds1.data-in.ru/Aggregated_datasets/Normotvorcheskii_process_v_RF_177_27.09.21/Normotvorcheskii_process_v_RF_177_27.09.21.zip'''\n",
    "with urllib.request.urlopen(url) as response, open(archive, 'wb') as out_file:\n",
    "    data = response.read() \n",
    "    out_file.write(data)\n",
    "    \n",
    "with zipfile.ZipFile(archive, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Вариант 2: полностью перегенерировать данные <a class=\"anchor\" id=\"full-data-gen\"></a>\n",
    "\n",
    "В этом варианте получения данных все данные будут сгенерированы из первоисточников с нуля. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Важно:</b> Если вы выполнили предыдущий пункт, этот проходить необзятельно.\n",
    "</div>\n",
    "\n",
    "[Перейти к следующей части](#norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачаем данные проектов на ОРВ\n",
    "\n",
    "#### Скачаем метаданные regulation.gov.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started adding projects to queue...\n",
      "Queue submitted.\n",
      "Scraper finished.\n",
      "Dumper is empty.\n",
      "Executors finished\n",
      "Tasks empty: True\n",
      "No tasks left\n",
      "No results left\n",
      "0:05:35.342103\n"
     ]
    }
   ],
   "source": [
    "!scraping/regulation_parser.py -c config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cкачаем файлы сводных отчетов и текстов НПА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=e02fae77-e413-48ba-8c34-4eadba58df06\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=db11aa88-8e30-4f67-a3b9-0f6847c95496\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=f373d334-9bba-4a42-adff-0e3ee8645606\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=c90fa8c7-3849-40e3-a83b-ee5fac3b89c8\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=693f94c2-b3ff-4c3c-a083-c2e8c4df9c10\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=9923c23e-1d27-4627-a3e0-27f2c78ae3cf\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=5f196052-0316-4697-b02a-5b6fcaba5c43\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=73dd9f31-3ce7-4b84-b6b3-bdf734e6aacf\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=80b6b5f2-22e6-4ec8-90e5-295b35fac5f4\n",
      "Task done\n",
      "Downloading https://regulation.gov.ru/Files/GetFile?fileid=832fe38a-0c42-4e81-a5b2-e88ac963da2f\n",
      "Task done\n",
      "No tasks left for this worker\n",
      "executors finished\n",
      "no tasks left\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "!scraping/download_files.py -c config.json -i orv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачаем данные законопроектов, внесенных в Госдуму\n",
    "\n",
    "#### Сбор метаданных по АПИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scraping/duma_parser.py -c config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Файлы законопроектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://sozd.duma.gov.ru/download/0A1FB15A-2CEB-44DC-8AC9-2A80A398D5EE\n",
      "Task done\n",
      "No tasks left for this worker\n",
      "executors finished\n",
      "no tasks left\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "!scraping/download_files.py -c config.json -i duma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соберём сводные отчёты из файлов\n",
    "\n",
    "На этом этапе мы с помощью библиотеки [report-parser]('https://github.com/CAG-ru/report_parser') преобразуем содержимое файлов, которые пока хранятся в формате отдельных файлов, в коллекцию питоновских объектов типа `Report` – то есть объектов, содержащих тексты и таблицы в формате `pandas.DataFrame`.\n",
    "\n",
    "Это долгий процесс, можете оставить скрипт работать, и пойти выпить самовар чаю – результаты на всякий случай сохранятся на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15096.docx File is not a zip file\n",
      "20367.pdf Расширение pdf не поддерживается\n"
     ]
    }
   ],
   "source": [
    "files_df = pd.DataFrame(columns=['regulation_project_id',\n",
    "                                'relative_path'])\n",
    "\n",
    "for degree in ['Низкая', 'Высокая', 'Средняя']:\n",
    "    files_dir = os.path.join(workdir, \n",
    "                            'scraping/main_ria_report') + '_' + degree   \n",
    "    pickled_path = os.path.join(workdir, \n",
    "                            'scraping/preparsed_reports') + '_' + degree\n",
    "    \n",
    "    reports = []\n",
    "    \n",
    "    for fn in os.listdir(files_dir):\n",
    "        report_path = os.path.join(files_dir, fn)\n",
    "        project_id = int(os.path.splitext(fn)[0])\n",
    "        files_df = files_df.append(pd.Series({\n",
    "            'regulation_project_id': project_id,\n",
    "            'relative_path' : report_path\n",
    "            }), ignore_index=True)\n",
    "        try:\n",
    "            report= Report(report_path)\n",
    "            report.parse()\n",
    "            reports.append((project_id, report))\n",
    "        except Exception as e:\n",
    "            print(fn, e)\n",
    "            \n",
    "    with open(pickled_path, 'wb') as f:\n",
    "        pickle.dump(reports, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Структурируем данные сводных отчетов\n",
    "\n",
    "На этом этапе проведём парсинг объектов типа `Report` в плоские таблицы: 1 основную и 15 вспомогательных.\n",
    "В основной таблице одной строчке соответствует сводный отчёт одного проекта, а колонки соответствуют графам отчёта, которые не предполагают множественных ответов.\n",
    "\n",
    "В случаях, когда графа отчёта может быть заполнена целым списком значений (например, «Цели предполагаемого регулирования»), для неё создаётся отдельная таблица с `one-to-many` соответствием: например, одному и тому же отчёту могут соответствовать несколько строк с разными целями регулирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заберем метаинформацию, она поможет нам с парсингом\n",
    "\n",
    "db = DBHelper(config['database'])\n",
    "query = '''\n",
    "    SELECT regulation_project_id, regulatory_impact\n",
    "    FROM public.project\n",
    "'''\n",
    "task = pd.DataFrame(db.select_statement(query),\n",
    "                   columns=['regulation_project_id', \n",
    "                            'impact_degree'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подцепим назад записанные на диск Report'ы\n",
    "\n",
    "reports = []\n",
    "for degree in ['Низкая', 'Высокая', 'Средняя']:\n",
    "    pickled_dir = os.path.join(workdir, \n",
    "                               'scraping/preparsed_reports') + '_' + degree \n",
    "    reports.extend(pickle.load(open(pickled_dir, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим пустые датафреймы, куда будем складывать результаты\n",
    "\n",
    "with open(\"gathering/df_primers\", \"rb\") as f:\n",
    "    df_primers = pickle.load(f)\n",
    "main_df = df_primers[\"main_df\"]\n",
    "otm_tables = df_primers[\"otm_tables\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустим парсеры, которые структурируют информацию из отчетов\n",
    "\n",
    "from gather_to_dataframe_utils import add_report_to_df, fill_blanks\n",
    "\n",
    "bad_reports = []\n",
    "for project_id, report in reports:\n",
    "    main_df = add_report_to_df(project_id, report, main_df, otm_tables, bad_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим лишние колонки – они возникают, когда кто-то случайно создает лишний заголовок в отчете\n",
    "main_df = main_df.iloc[:, :73]\n",
    "\n",
    "# Непустой 'header: id' – хороший предиктор адекватности отчета, \n",
    "# т.к. он заполняется автоматически и должен быть всегда\n",
    "main_df = main_df[~main_df['header: id'].isnull()]\n",
    "\n",
    "# Добавим нужные колонки и удалим ненужные\n",
    "main_df.drop(['header: id', 'header: regulation_project_id',\n",
    "              'header: start', 'header: end'], \n",
    "             inplace=True, axis=1)\n",
    "main_df = main_df.merge(task, on='regulation_project_id', how='inner')\n",
    "\n",
    "# Пометим специальным значением non-applicable графы, которые и не должны были быть заполнены\n",
    "main_df = main_df.apply(fill_blanks, axis=1)\n",
    "# Степень регулирующего воздействия больше не нужна\n",
    "main_df.drop(['impact_degree'], \n",
    "             inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from orv_cleanup_utils import *\n",
    "\n",
    "for column in main_df.columns:\n",
    "    main_df[column] = main_df[column].apply(remove_standard_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишем данные в ту же директорию, как если бы мы их скачали\n",
    "\n",
    "parsed_dir = os.path.join(workdir, 'datasets/')\n",
    "\n",
    "os.makedirs(parsed_dir, exist_ok=True)\n",
    "\n",
    "main_df.to_csv(os.path.join(parsed_dir, 'ria_reports_main.csv'), \n",
    "             index=False)\n",
    "\n",
    "for otm_name, otm_df in otm_tables.items():\n",
    "    if otm_name == 'business':\n",
    "        otm_df[0].to_csv(os.path.join(parsed_dir,\n",
    "                'ria_reports_business_sizes_as_is.csv'), \n",
    "                index=False)\n",
    "        otm_df[1].to_csv(os.path.join(parsed_dir,\n",
    "                'ria_reports_business_profit_loss.csv'), \n",
    "                index=False)\n",
    "        otm_df[1].to_csv(os.path.join(parsed_dir,\n",
    "            'ria_reports_business_sizes_to_be.csv'), \n",
    "             index=False)\n",
    "        continue\n",
    "        \n",
    "    otm_df.to_csv(os.path.join(parsed_dir, 'ria_reports_' \\\n",
    "                               + otm_name + '.csv'), \n",
    "                               index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация <a class=\"anchor\" id=\"norm\"></a>\n",
    "\n",
    "Вы дошли до нормализации – вы восхитительны!\n",
    "\n",
    "Во время нормализации происходит разметка на пустые, несодержательные и содержательные заполнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговая разметка мусорных и отсутствующих заполнений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разметка пустых, несодежрательных заполнений происходила следующим образом. Типичные кандидаты в «мусор», как правило, представляют собой наиболее частые и/или короткие заполнения в каждой графе. Для их отлова нам понадобятся `most_freq` и `shortest` из `orv_cleanup_utils`.\n",
    "2. После применения этих функций к каждой из граф было взяты по топ-`50` самых частых и самых коротких заполнений. Таблицы с ними и были направлены экспертам.\n",
    "3. Эксперты разметили каждое заполнение графы `0` или `1` - в зависимости от содержательности заполнения.\n",
    "4. Заполнения, отмеченные `0`, были взяты в качестве негативной оценки заполненности графы.\n",
    "5. Все графы были размечены по своим \"словарикам\" правильных и неправильных ответов.\n",
    "6. Документ `junk_by_field.json` содержит негативные заполнения по каждому из полей формы, а `mapping_fields.json` позволяет по короткому наименованию поля получить расширенное - то, которое использовалось в отчёте.\n",
    "7. В результате обработки были созданы таблицы, каждая из которых содержит оригинальное заполнение, а также проставленную оценку в соседнем столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим датасеты\n",
    "\n",
    "data_dir = os.path.join(workdir, 'datasets/')\n",
    "main_df = pd.read_csv(data_dir + 'ria_reports_main.csv', encoding='utf-8', delimiter=';')\n",
    "\n",
    "otm_tables_fnames = sorted([fn for fn in os.listdir(data_dir) if not (fn.startswith('main') or fn.startswith('.'))])\n",
    "otm_tables = {fn[:-4]: pd.read_csv(data_dir + fn, encoding='utf-8', delimiter=';') for fn in otm_tables_fnames}\n",
    "otm_tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from normalization.orv_cleanup_utils import fill_df_info\n",
    "\n",
    "\n",
    "with open('normalization/junk/mapping_fields.json', 'r') as fp:\n",
    "    all_fields = json.load(fp)\n",
    "    \n",
    "\n",
    "# junk_main_df = fill_df_info(all_fields, main_df, 'main')\n",
    "# junk_main_df.to_excel('normalization/junk/junk_main_df.xlsx', header=True)\n",
    "\n",
    "for _ in otm_tables.keys():\n",
    "    short_name = _.replace('ria_reports_', '')\n",
    "    if short_name in all_fields.keys():\n",
    "        df = otm_tables.get(_)\n",
    "        print(_)\n",
    "        result = fill_df_info(all_fields, df, short_name)\n",
    "        result.to_excel(f'normalization/junk/junk_{_}_df.xlsx', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
